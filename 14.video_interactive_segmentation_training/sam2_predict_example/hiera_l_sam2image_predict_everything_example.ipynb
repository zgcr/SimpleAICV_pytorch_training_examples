{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "inference_ipynb_path='/root/code/SimpleAICV_pytorch_training_examples/14.video_interactive_segmentation_training/sam2_predict_example'\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(inference_ipynb_path))\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from SimpleAICV.video_interactive_segmentation.models.segment_anything2.sam2image import hiera_l_sam2image\n",
    "from SimpleAICV.video_interactive_segmentation.common import load_state_dict\n",
    "\n",
    "\n",
    "sam_checkpoint = '/root/autodl-tmp/pretrained_models/sam2.1_convert_from_pytorch_official_weights/sam2.1_hiera_large_convert_from_pytorch_official_weight.pth'\n",
    "\n",
    "sam_model = hiera_l_sam2image()\n",
    "sam_model = sam_model.cuda()\n",
    "sam_model = sam_model.eval()\n",
    "\n",
    "load_state_dict(sam_checkpoint,sam_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path='/root/code/SimpleAICV_pytorch_training_examples/14.video_interactive_segmentation_training/sam2_predict_example/test_images/dogs.jpg'\n",
    "origin_image = cv2.imdecode(np.fromfile(test_image_path, dtype=np.uint8),\n",
    "                        cv2.IMREAD_COLOR)\n",
    "origin_image = cv2.cvtColor(origin_image, cv2.COLOR_BGR2RGB)\n",
    "print(origin_image.shape,origin_image.dtype)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(origin_image)\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_h, origin_w = origin_image.shape[0], origin_image.shape[1]\n",
    "h_factor = 1024 / origin_h\n",
    "w_factor = 1024 / origin_w\n",
    "resized_image = cv2.resize(origin_image, (1024, 1024))\n",
    "print(resized_image.shape,resized_image.dtype,h_factor,w_factor)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(resized_image)\n",
    "plt.axis('on')\n",
    "plt.show()\n",
    "\n",
    "mean = [123.675, 116.28, 103.53]\n",
    "std = [58.395, 57.12, 57.375]\n",
    "norm_image = (resized_image - mean) / std\n",
    "print(norm_image.shape,np.max(norm_image),np.min(norm_image))\n",
    "\n",
    "padded_img = np.zeros((1024, 1024, 3),\n",
    "                        dtype=np.float32)\n",
    "padded_img[:, :, :] = norm_image\n",
    "print(padded_img.shape,np.max(padded_img),np.min(padded_img))\n",
    "\n",
    "padded_img = torch.tensor(padded_img).float().cuda().permute(2, 0, 1).unsqueeze(0)\n",
    "print(padded_img.shape,torch.max(padded_img),torch.min(padded_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I64YhiKsS2KU"
   },
   "outputs": [],
   "source": [
    "grid_size = 32\n",
    "positive_grid_points = []\n",
    "positive_grid_labels = []\n",
    "for i in range(grid_size):\n",
    "    per_point_x = 0.5 + i / grid_size * origin_w\n",
    "    for j in range(grid_size):\n",
    "        per_point_y = 0.5 + j / grid_size * origin_h\n",
    "        positive_grid_points.append([per_point_x, per_point_y])\n",
    "        positive_grid_labels.append([1])\n",
    "\n",
    "positive_grid_points = np.array(positive_grid_points)\n",
    "positive_grid_points[:,0] = positive_grid_points[:,0]*w_factor\n",
    "positive_grid_points[:,1] = positive_grid_points[:,1]*h_factor\n",
    "positive_grid_labels = np.array(positive_grid_labels)\n",
    "print(grid_size,origin_h,origin_w,positive_grid_points.shape,positive_grid_labels.shape)\n",
    "\n",
    "prompt_points = np.concatenate([positive_grid_points,positive_grid_labels],axis=1)\n",
    "print(prompt_points.shape)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(resized_image)\n",
    "show_points(positive_grid_points, np.squeeze(positive_grid_labels,axis=1), plt.gca())\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_images = padded_img.clone()\n",
    "\n",
    "with torch.no_grad():\n",
    "    per_image_embedding = sam_model.forward_image_encoder(per_images)\n",
    "print(per_image_embedding[0].shape, per_image_embedding[1].shape, per_image_embedding[2].shape)\n",
    "\n",
    "batch_mask_preds = []\n",
    "batch_iou_preds = []\n",
    "for per_point in prompt_points:\n",
    "    per_point = np.expand_dims(per_point, axis=0)\n",
    "    per_prompt_point = torch.tensor(np.expand_dims(per_point,\n",
    "                                                   axis=0)).float().cuda()\n",
    "    per_prompt = {\n",
    "        'prompt_point': per_prompt_point,\n",
    "        'prompt_box': None,\n",
    "        'prompt_mask': None\n",
    "    }\n",
    "    mask_out_idxs = [0]\n",
    "    with torch.no_grad():\n",
    "        mask_preds, iou_preds = sam_model.forward_prompt_encoder_mask_decoder(\n",
    "            per_image_embedding, per_prompt, mask_out_idxs=mask_out_idxs)\n",
    "        mask_preds, iou_preds = mask_preds[0], iou_preds[0]\n",
    "\n",
    "    batch_mask_preds.append(mask_preds)\n",
    "    batch_iou_preds.append(iou_preds)\n",
    "print(len(batch_mask_preds), batch_mask_preds[0].shape, len(batch_iou_preds), batch_iou_preds[0].shape)\n",
    "\n",
    "batch_mask_preds = torch.cat(batch_mask_preds, dim=0)\n",
    "batch_iou_preds = torch.cat(batch_iou_preds, dim=0)\n",
    "batch_mask_preds = batch_mask_preds.cpu().numpy()\n",
    "batch_iou_preds = batch_iou_preds.cpu().numpy()\n",
    "\n",
    "# [mask_num,mask_h,mask_w],[mask_num]\n",
    "print(batch_mask_preds.shape, batch_iou_preds.shape, batch_iou_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_masks_stability_score(masks, mask_threshold, threshold_offset):\n",
    "    \"\"\"\n",
    "    Computes the stability score for a batch of masks. The stability\n",
    "    score is the IoU between the binary masks obtained by thresholding\n",
    "    the predicted mask logits at high and low values.\n",
    "    \"\"\"\n",
    "    intersections = np.sum(np.sum((masks >\n",
    "                                   (mask_threshold + threshold_offset)),\n",
    "                                  axis=-1),\n",
    "                           axis=-1)\n",
    "    unions = np.sum(np.sum((masks > (mask_threshold - threshold_offset)),\n",
    "                           axis=-1),\n",
    "                    axis=-1)\n",
    "\n",
    "    return intersections / unions\n",
    "\n",
    "\n",
    "def filter_small_area_masks(masks, ious, filter_area_ratio=0.0001):\n",
    "    per_mask_h, per_mask_w = masks.shape[1], masks.shape[2]\n",
    "    masks_area = np.sum(masks, axis=(1, 2))\n",
    "\n",
    "    keep_masks = []\n",
    "    keep_ious = []\n",
    "    for per_mask_area, per_mask, per_iou in zip(masks_area, masks, ious):\n",
    "        per_mask_area_ratio = per_mask_area / float(per_mask_h * per_mask_w)\n",
    "\n",
    "        if per_mask_area_ratio > filter_area_ratio:\n",
    "            keep_masks.append(per_mask)\n",
    "            keep_ious.append(per_iou)\n",
    "\n",
    "    keep_masks = np.array(keep_masks)\n",
    "    keep_ious = np.array(keep_ious)\n",
    "\n",
    "    return keep_masks, keep_ious\n",
    "\n",
    "\n",
    "def fill_masks_hole(masks, fill_area_threshold=100):\n",
    "    filled_masks = []\n",
    "    for per_mask in masks:\n",
    "        per_mask = per_mask.astype(np.uint8)\n",
    "        # 取反mask,因为我们要填充的是前景中的空洞\n",
    "        mask_invert = 1 - per_mask\n",
    "\n",
    "        # 寻找连通区域\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(\n",
    "            mask_invert, 8, cv2.CV_32S)\n",
    "\n",
    "        # Row 0 is background label\n",
    "        sizes = stats[:, -1][1:]\n",
    "        small_regions = [\n",
    "            i + 1 for i, s in enumerate(sizes) if s < fill_area_threshold\n",
    "        ]\n",
    "        if len(small_regions) == 0:\n",
    "            filled_masks.append(per_mask)\n",
    "        else:\n",
    "            fill_labels = [0] + small_regions\n",
    "            per_mask = np.isin(labels, fill_labels).astype(np.uint8)\n",
    "            filled_masks.append(per_mask)\n",
    "\n",
    "    filled_masks = np.array(filled_masks)\n",
    "\n",
    "    return filled_masks\n",
    "\n",
    "\n",
    "def calculate_mask_nms(sorted_masks, sorted_scores, nms_threshold=0.5):\n",
    "    '''\n",
    "    sorted_masks:[mask_nums,mask_h,mask_w]\n",
    "    sorted_scores:[mask_nums],mask predict scores\n",
    "    '''\n",
    "    sorted_masks_area = np.sum(sorted_masks, axis=(1, 2))\n",
    "\n",
    "    indexes = np.array([i for i in range(sorted_scores.shape[0])],\n",
    "                       dtype=np.int32)\n",
    "\n",
    "    keep = []\n",
    "    while indexes.shape[0] > 0:\n",
    "        keep_idx = indexes[0]\n",
    "        keep.append(keep_idx)\n",
    "        indexes = indexes[1:]\n",
    "        if len(indexes) == 0:\n",
    "            break\n",
    "\n",
    "        keep_mask_area = sorted_masks_area[keep_idx]\n",
    "\n",
    "        overlap_mask_area = np.sum((sorted_masks[keep_idx]\n",
    "                                    & sorted_masks[indexes]),\n",
    "                                   axis=(1, 2))\n",
    "        union_mask_area = keep_mask_area + sorted_masks_area[\n",
    "            indexes] - overlap_mask_area\n",
    "        union_mask_area = np.maximum(union_mask_area, 1e-4)\n",
    "        ious = overlap_mask_area / union_mask_area\n",
    "\n",
    "        candidate_indexes = np.where(ious < nms_threshold)[0]\n",
    "        indexes = indexes[candidate_indexes]\n",
    "\n",
    "    keep = np.array(keep)\n",
    "\n",
    "    return keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_pred_filter_threshold = 0.9\n",
    "pred_masks = batch_mask_preds[batch_iou_preds > iou_pred_filter_threshold]\n",
    "pred_ious = batch_iou_preds[batch_iou_preds > iou_pred_filter_threshold]\n",
    "print('1111',pred_masks.shape,pred_ious.shape,pred_ious[0])\n",
    "\n",
    "mask_stability_score_filter_threshold=0.9\n",
    "pred_mask_stability_scores = calculate_masks_stability_score(pred_masks, 0.0, 1.0)\n",
    "pred_masks = pred_masks[pred_mask_stability_scores>mask_stability_score_filter_threshold]\n",
    "pred_ious = pred_ious[pred_mask_stability_scores>mask_stability_score_filter_threshold]\n",
    "print('2222',pred_masks.shape,pred_ious.shape,pred_ious[0])\n",
    "\n",
    "pred_masks= (pred_masks > 0).astype(np.uint8)\n",
    "print('3333',pred_masks.shape,pred_ious.shape,pred_ious[0],np.unique(pred_masks))\n",
    "\n",
    "fill_area_threshold=100\n",
    "pred_masks=fill_masks_hole(pred_masks,fill_area_threshold=fill_area_threshold).astype(np.uint8)\n",
    "print('4444',pred_masks.shape,pred_ious.shape,pred_ious[0],np.unique(pred_masks))\n",
    "\n",
    "filter_area_ratio=0.0001\n",
    "pred_masks,pred_ious=filter_small_area_masks(pred_masks, pred_ious, filter_area_ratio=filter_area_ratio)\n",
    "print('5555',pred_masks.shape,pred_ious.shape,pred_ious[0],np.unique(pred_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descending sort\n",
    "iou_sorted_indexes = np.argsort(-pred_ious)\n",
    "pred_masks = pred_masks[iou_sorted_indexes]\n",
    "pred_ious = pred_ious[iou_sorted_indexes]\n",
    "print('6666',pred_masks.shape,pred_ious.shape,pred_ious[0])\n",
    "\n",
    "nms_threshold=0.3\n",
    "keep_mask_indexes=calculate_mask_nms(pred_masks, pred_ious, nms_threshold=nms_threshold)\n",
    "pred_masks = pred_masks[keep_mask_indexes]\n",
    "pred_ious = pred_ious[keep_mask_indexes]\n",
    "print('7777',keep_mask_indexes.shape,pred_masks.shape,pred_ious.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(resized_image)\n",
    "for i, per_mask in enumerate(pred_masks):\n",
    "    show_mask(per_mask, plt.gca(), random_color=True)\n",
    "plt.axis('off')\n",
    "plt.show()  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "custom": {
   "cells": [],
   "metadata": {
    "custom": {
     "cells": [],
     "metadata": {
      "accelerator": "GPU",
      "colab": {
       "machine_shape": "hm",
       "provenance": []
      },
      "fileHeader": "",
      "fileUid": "f337ddbb-4ec7-4bc4-8c8b-f31305249752",
      "isAdHoc": false,
      "kernelspec": {
       "display_name": "Python 3",
       "name": "python3"
      },
      "language_info": {
       "name": "python"
      }
     },
     "nbformat": 4,
     "nbformat_minor": 0
    },
    "fileHeader": "",
    "fileUid": "e9a56628-4146-43e5-85f7-3d332cf3b1a2",
    "indentAmount": 2,
    "isAdHoc": false,
    "language_info": {
     "name": "plaintext"
    }
   },
   "nbformat": 4,
   "nbformat_minor": 2
  },
  "indentAmount": 2,
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
