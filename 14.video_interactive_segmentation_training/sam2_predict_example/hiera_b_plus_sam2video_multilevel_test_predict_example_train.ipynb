{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ba49d8-8c22-4eba-a2ab-46eee839287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def show_mask(mask, ax, obj_id=None, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        cmap = plt.get_cmap(\"tab10\")\n",
    "        cmap_idx = 0 if obj_id is None else obj_id\n",
    "        color = np.array([*cmap(cmap_idx)[:3], 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=200):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "\n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0, 0, 0, 0), lw=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8e0779-751f-4224-9b04-ed0f0b406500",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f3245e-b4d6-418b-a42a-a67e0b3b5aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "inference_ipynb_path='/root/code/SimpleAICV_pytorch_training_examples/14.video_interactive_segmentation_training/sam2_predict_example'\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(inference_ipynb_path))\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from SimpleAICV.video_interactive_segmentation.models.segment_anything2.sam2video_test import hiera_b_plus_sam2video_test\n",
    "from SimpleAICV.video_interactive_segmentation.common import load_state_dict\n",
    "\n",
    "sam2_checkpoint = '/root/autodl-tmp/pretrained_models/sam2_segmentation_train_on_video_interactive_segmentation_dataset/hiera_b_plus_sam2video_multilevel_stage3_epoch_20.pth'\n",
    "\n",
    "sam2_model = hiera_b_plus_sam2video_test()\n",
    "sam2_model = sam2_model.cuda()\n",
    "sam2_model = sam2_model.eval()\n",
    "\n",
    "load_state_dict(sam2_checkpoint, sam2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94c87ca-fd1a-4011-9609-e8be1cbe3230",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir_path = '/root/code/SimpleAICV_pytorch_training_examples/14.video_interactive_segmentation_training/sam2_predict_example/test_videos/bedroom'\n",
    "\n",
    "frames_name_list = []\n",
    "for per_frame_name in os.listdir(video_dir_path):\n",
    "    if '.jpg' in per_frame_name:\n",
    "        frames_name_list.append(per_frame_name)\n",
    "frames_name_list = sorted(frames_name_list)\n",
    "frames_path_list = [\n",
    "    os.path.join(video_dir_path, n) for n in frames_name_list\n",
    "]\n",
    "\n",
    "vis_frame_stride = 30\n",
    "for frame_idx in range(0, len(frames_path_list), vis_frame_stride):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.title(f\"frame: {frame_idx}\")\n",
    "    show_image = Image.open(frames_path_list[frame_idx])\n",
    "    plt.imshow(show_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff46b10-c17a-4a26-8004-8c6d80806b0a",
   "metadata": {},
   "source": [
    "# Init Video State Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8967aed3-eb82-4866-b8df-0f4743255c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_state_dict = sam2_model.init_video_state_dict(video_dir_path=video_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb1f3f6-d74d-4016-934c-8d2a14d1a543",
   "metadata": {},
   "source": [
    "# Clear Video State Dict All Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2646a1d-3401-438c-a653-55e0e56b7d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_state_dict = sam2_model.clear_video_state_dict_all_info(video_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aeb04d-8cba-4f57-95da-6e5a1796003e",
   "metadata": {},
   "source": [
    "# Init Video State Dict Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f255b20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_state_dict = sam2_model.init_video_state_dict(video_dir_path=video_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695c7749-b523-4691-aad0-7558c5d1d68c",
   "metadata": {},
   "source": [
    "# Add one object with one point prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e749bab-0f36-4173-bf8d-0c20cd5214b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx = 0\n",
    "\n",
    "# Let's add a positive click at (x, y) = (210, 350) to get started, for labels, `1` means positive click and `0` means negative click\n",
    "input_point = np.array([[210, 350]], dtype=np.float32)\n",
    "input_label = np.array([[1]], dtype=np.int32)\n",
    "print(input_point.shape, input_label.shape)\n",
    "\n",
    "input_prompt_point = np.concatenate([input_point, input_label], axis=1, dtype=np.float32)\n",
    "input_prompt_point = np.expand_dims(input_prompt_point, axis=0)\n",
    "print(input_prompt_point.shape,input_prompt_point.dtype)\n",
    "\n",
    "exist_object_ids, frame_idx, new_object_id, has_prompt_point, has_prompt_box, has_prompt_mask = sam2_model.add_new_object_prompt_input(\n",
    "                                    video_state_dict,\n",
    "                                    frame_idx=frame_idx,\n",
    "                                    prompt_point=input_prompt_point,\n",
    "                                    prompt_box=None,\n",
    "                                    prompt_mask=None)\n",
    "print(exist_object_ids, frame_idx, new_object_id, has_prompt_point, has_prompt_box, has_prompt_mask)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.title(f\"frame: {frame_idx}\")\n",
    "show_image = Image.open(frames_path_list[frame_idx])\n",
    "plt.imshow(show_image)\n",
    "show_points(input_point, input_label[0], plt.gca())\n",
    "\n",
    "mask_preds, iou_preds = sam2_model.forward_one_image_test(video_state_dict, new_object_id, frame_idx, mask_out_idxs=[0, 1, 2, 3])\n",
    "mask_preds, iou_preds = mask_preds[0], iou_preds[0]\n",
    "binary_mask_preds = mask_preds > 0.\n",
    "print(binary_mask_preds.shape,iou_preds.shape,iou_preds)\n",
    "\n",
    "for i, (mask, score) in enumerate(zip(binary_mask_preds, iou_preds)):\n",
    "    mask=mask.cpu().float().numpy()\n",
    "    score=score.cpu().float().numpy()\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    show_image = Image.open(frames_path_list[frame_idx])\n",
    "    plt.imshow(show_image)\n",
    "    show_mask(mask, plt.gca(), obj_id=new_object_id)\n",
    "    show_points(input_point, input_label[0], plt.gca())\n",
    "    plt.title(f\"frame: {frame_idx}, Mask: {i+1},IoU Score: {score:.3f}\", fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89457875-93fa-40ed-b6dc-4e1c971a27f9",
   "metadata": {},
   "source": [
    "# Tracking one object with one point prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ab3ec7-2537-4158-bf98-3d0977d8908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_object_id = 0\n",
    "video_state_dict = sam2_model.forward_tracking_for_test(video_state_dict, start_tracking_frame_idx=0, tracking_object_ids=[tracking_object_id], use_point_prompt_input=True,use_box_prompt_input=False, use_mask_prompt_input=False)\n",
    "\n",
    "frame_num = video_state_dict['video_frame_num']\n",
    "object_track_state = video_state_dict['object_track_state'][tracking_object_id]\n",
    "object_track_result = video_state_dict['object_track_result'][tracking_object_id]\n",
    "print(frame_num, object_track_state)\n",
    "\n",
    "vis_frame_stride = 30\n",
    "for frame_idx in range(0, len(frames_path_list), vis_frame_stride):\n",
    "    per_frame_object_result = object_track_result[frame_idx]\n",
    "    per_frame_per_object_mask = per_frame_object_result['pred_mask']\n",
    "    per_frame_per_object_iou = per_frame_object_result['pred_iou']\n",
    "    per_frame_per_object_score = per_frame_object_result['pred_object_score']\n",
    "\n",
    "    per_frame_per_object_mask = per_frame_per_object_mask > 0.\n",
    "\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    show_image = Image.open(frames_path_list[frame_idx])\n",
    "    plt.imshow(show_image)\n",
    "    show_mask(per_frame_per_object_mask, plt.gca(), obj_id=tracking_object_id)\n",
    "    plt.title(\n",
    "        f\"frame: {frame_idx}, IoU Score: {per_frame_per_object_iou:.3f}, Object Score: {per_frame_per_object_score:.3f}\",\n",
    "        fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4ab457-d91d-4ac8-b350-fbcd549fd3fd",
   "metadata": {},
   "source": [
    "# Add one object with two point prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab45e932-b0d5-4983-9718-6ee77d1ac31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx = 0\n",
    "\n",
    "# Let's add a positive click at (x, y) = (210, 350) to get started, for labels, `1` means positive click and `0` means negative click\n",
    "input_point = np.array([[210, 350], [250, 220]], dtype=np.float32)\n",
    "input_label = np.array([[1], [1]], dtype=np.int32)\n",
    "print(input_point.shape, input_label.shape)\n",
    "\n",
    "input_prompt_point = np.concatenate([input_point, input_label], axis=1, dtype=np.float32)\n",
    "input_prompt_point = np.expand_dims(input_prompt_point, axis=0)\n",
    "print(input_prompt_point.shape,input_prompt_point.dtype)\n",
    "\n",
    "exist_object_ids, frame_idx, new_object_id, has_prompt_point, has_prompt_box, has_prompt_mask = sam2_model.add_new_object_prompt_input(\n",
    "                                    video_state_dict,\n",
    "                                    frame_idx=frame_idx,\n",
    "                                    prompt_point=input_prompt_point,\n",
    "                                    prompt_box=None,\n",
    "                                    prompt_mask=None)\n",
    "print(exist_object_ids, frame_idx, new_object_id, has_prompt_point, has_prompt_box, has_prompt_mask)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.title(f\"frame {frame_idx}\")\n",
    "show_image = Image.open(frames_path_list[frame_idx])\n",
    "plt.imshow(show_image)\n",
    "show_points(input_point, np.squeeze(input_label,axis=1), plt.gca())\n",
    "\n",
    "mask_preds, iou_preds = sam2_model.forward_one_image_test(video_state_dict, new_object_id, frame_idx, mask_out_idxs=[0])\n",
    "mask_preds, iou_preds = mask_preds[0][0], iou_preds[0][0]\n",
    "binary_mask_preds = mask_preds > 0.\n",
    "binary_mask_preds = binary_mask_preds.cpu().float().numpy()\n",
    "iou_preds = iou_preds.cpu().float().numpy()\n",
    "print(binary_mask_preds.shape,iou_preds.shape,iou_preds)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "show_image = Image.open(frames_path_list[frame_idx])\n",
    "plt.imshow(show_image)\n",
    "show_mask(binary_mask_preds, plt.gca())\n",
    "show_points(input_point, np.squeeze(input_label,axis=1), plt.gca())\n",
    "plt.title(f\"frame {frame_idx}, Score: {iou_preds:.3f}\", fontsize=18)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e801b70-72df-4a72-b3fe-84f145e5e3f6",
   "metadata": {},
   "source": [
    "# Tracking one object with two point prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a572ea9-5b7e-479c-b30c-93c38b121131",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_object_id = 1\n",
    "video_state_dict = sam2_model.forward_tracking_for_test(video_state_dict, start_tracking_frame_idx=0, tracking_object_ids=[tracking_object_id], use_point_prompt_input=True,use_box_prompt_input=False, use_mask_prompt_input=False)\n",
    "\n",
    "frame_num = video_state_dict['video_frame_num']\n",
    "object_track_state = video_state_dict['object_track_state'][tracking_object_id]\n",
    "object_track_result = video_state_dict['object_track_result'][tracking_object_id]\n",
    "print(frame_num, object_track_state)\n",
    "\n",
    "vis_frame_stride = 30\n",
    "for frame_idx in range(0, len(frames_path_list), vis_frame_stride):\n",
    "    per_frame_object_result = object_track_result[frame_idx]\n",
    "    per_frame_per_object_mask = per_frame_object_result['pred_mask']\n",
    "    per_frame_per_object_iou = per_frame_object_result['pred_iou']\n",
    "    per_frame_per_object_score = per_frame_object_result['pred_object_score']\n",
    "\n",
    "    per_frame_per_object_mask = per_frame_per_object_mask > 0.\n",
    "\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    show_image = Image.open(frames_path_list[frame_idx])\n",
    "    plt.imshow(show_image)\n",
    "    show_mask(per_frame_per_object_mask, plt.gca(), obj_id=tracking_object_id)\n",
    "    plt.title(\n",
    "        f\"frame: {frame_idx}, IoU Score: {per_frame_per_object_iou:.3f}, Object Score: {per_frame_per_object_score:.3f}\",\n",
    "        fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a3950a-acf1-435c-bd64-94297267b5e9",
   "metadata": {},
   "source": [
    "# Clear Video State Dict All Object Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa96690-4a38-4a24-aa17-fd2f4db0e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_state_dict = sam2_model.clear_video_state_dict_all_object_info(video_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2502bb5a-3e1f-43d0-9f58-33f8676fff0d",
   "metadata": {},
   "source": [
    "# Add one object with box prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbe9183-abbb-4283-b0cb-d24f3d7beb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx = 0\n",
    "\n",
    "# Let's add a box at (x_min, y_min, x_max, y_max) = (300, 0, 500, 400) to get started\n",
    "input_box = np.array([300, 0, 500, 400], dtype=np.float32)\n",
    "print(input_box.shape)\n",
    "\n",
    "input_prompt_box = np.expand_dims(input_box, axis=0)\n",
    "print(input_prompt_box.shape,input_prompt_box.dtype)\n",
    "\n",
    "exist_object_ids, frame_idx, new_object_id, has_prompt_point, has_prompt_box, has_prompt_mask = sam2_model.add_new_object_prompt_input(\n",
    "                                    video_state_dict,\n",
    "                                    frame_idx=frame_idx,\n",
    "                                    prompt_point=None,\n",
    "                                    prompt_box=input_prompt_box,\n",
    "                                    prompt_mask=None)\n",
    "print(exist_object_ids, frame_idx, new_object_id, has_prompt_point, has_prompt_box, has_prompt_mask)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.title(f\"frame {frame_idx}\")\n",
    "show_image = Image.open(frames_path_list[frame_idx])\n",
    "plt.imshow(show_image)\n",
    "show_box(input_box, plt.gca())\n",
    "\n",
    "mask_preds, iou_preds = sam2_model.forward_one_image_test(video_state_dict, new_object_id, frame_idx, mask_out_idxs=[0])\n",
    "mask_preds, iou_preds = mask_preds[0][0], iou_preds[0][0]\n",
    "binary_mask_preds = mask_preds > 0.\n",
    "binary_mask_preds = binary_mask_preds.cpu().float().numpy()\n",
    "iou_preds = iou_preds.cpu().float().numpy()\n",
    "print(binary_mask_preds.shape,iou_preds.shape,iou_preds)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "show_image = Image.open(frames_path_list[frame_idx])\n",
    "plt.imshow(show_image)\n",
    "show_mask(binary_mask_preds, plt.gca())\n",
    "show_box(input_box, plt.gca())\n",
    "plt.title(f\"frame {frame_idx}, Score: {iou_preds:.3f}\", fontsize=18)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb6eae9-0f4c-434f-8089-a46c9ca59da5",
   "metadata": {},
   "source": [
    "# Tracking one object with box prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbfb273-4e14-495b-bd89-87a8baf52ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_object_id = 0\n",
    "video_state_dict = sam2_model.forward_tracking_for_test(video_state_dict, start_tracking_frame_idx=0, tracking_object_ids=[tracking_object_id], use_point_prompt_input=False,use_box_prompt_input=True, use_mask_prompt_input=False)\n",
    "\n",
    "frame_num = video_state_dict['video_frame_num']\n",
    "object_track_state = video_state_dict['object_track_state'][tracking_object_id]\n",
    "object_track_result = video_state_dict['object_track_result'][tracking_object_id]\n",
    "print(frame_num, object_track_state)\n",
    "\n",
    "vis_frame_stride = 30\n",
    "for frame_idx in range(0, len(frames_path_list), vis_frame_stride):\n",
    "    per_frame_object_result = object_track_result[frame_idx]\n",
    "    per_frame_per_object_mask = per_frame_object_result['pred_mask']\n",
    "    per_frame_per_object_iou = per_frame_object_result['pred_iou']\n",
    "    per_frame_per_object_score = per_frame_object_result['pred_object_score']\n",
    "\n",
    "    per_frame_per_object_mask = per_frame_per_object_mask > 0.\n",
    "\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    show_image = Image.open(frames_path_list[frame_idx])\n",
    "    plt.imshow(show_image)\n",
    "    show_mask(per_frame_per_object_mask, plt.gca(), obj_id=tracking_object_id)\n",
    "    plt.title(\n",
    "        f\"frame: {frame_idx}, IoU Score: {per_frame_per_object_iou:.3f}, Object Score: {per_frame_per_object_score:.3f}\",\n",
    "        fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00756f3",
   "metadata": {},
   "source": [
    "# Clear Video State Dict All Object Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b35fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_state_dict = sam2_model.clear_video_state_dict_all_object_info(video_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a093575",
   "metadata": {},
   "source": [
    "# Add one object with box prompt at inter frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6bb645",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx = 60\n",
    "\n",
    "# Let's add a box at (x_min, y_min, x_max, y_max) = (300, 0, 500, 400) to get started\n",
    "input_box = np.array([180, 0, 450, 430], dtype=np.float32)\n",
    "print(input_box.shape)\n",
    "\n",
    "input_prompt_box = np.expand_dims(input_box, axis=0)\n",
    "print(input_prompt_box.shape,input_prompt_box.dtype)\n",
    "\n",
    "exist_object_ids, frame_idx, new_object_id, has_prompt_point, has_prompt_box, has_prompt_mask = sam2_model.add_new_object_prompt_input(\n",
    "                                    video_state_dict,\n",
    "                                    frame_idx=frame_idx,\n",
    "                                    prompt_point=None,\n",
    "                                    prompt_box=input_prompt_box,\n",
    "                                    prompt_mask=None)\n",
    "print(exist_object_ids, frame_idx, new_object_id, has_prompt_point, has_prompt_box, has_prompt_mask)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.title(f\"frame {frame_idx}\")\n",
    "show_image = Image.open(frames_path_list[frame_idx])\n",
    "plt.imshow(show_image)\n",
    "show_box(input_box, plt.gca())\n",
    "\n",
    "mask_preds, iou_preds = sam2_model.forward_one_image_test(video_state_dict, new_object_id, frame_idx, mask_out_idxs=[0])\n",
    "mask_preds, iou_preds = mask_preds[0][0], iou_preds[0][0]\n",
    "binary_mask_preds = mask_preds > 0.\n",
    "binary_mask_preds = binary_mask_preds.cpu().float().numpy()\n",
    "iou_preds = iou_preds.cpu().float().numpy()\n",
    "print(binary_mask_preds.shape, iou_preds.shape, iou_preds)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "show_image = Image.open(frames_path_list[frame_idx])\n",
    "plt.imshow(show_image)\n",
    "show_mask(binary_mask_preds, plt.gca())\n",
    "show_box(input_box, plt.gca())\n",
    "plt.title(f\"frame {frame_idx}, Score: {iou_preds:.3f}\", fontsize=18)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcd524f",
   "metadata": {},
   "source": [
    "# Tracking one object with box prompt at inter frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b747b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_object_id = 0\n",
    "video_state_dict = sam2_model.forward_tracking_for_test(video_state_dict, start_tracking_frame_idx=60, tracking_object_ids=[tracking_object_id], use_point_prompt_input=False,use_box_prompt_input=True, use_mask_prompt_input=False)\n",
    "\n",
    "frame_num = video_state_dict['video_frame_num']\n",
    "object_track_state = video_state_dict['object_track_state'][tracking_object_id]\n",
    "object_track_result = video_state_dict['object_track_result'][tracking_object_id]\n",
    "print(frame_num, object_track_state)\n",
    "\n",
    "vis_frame_stride = 30\n",
    "for frame_idx in range(0, len(frames_path_list), vis_frame_stride):\n",
    "    per_frame_object_result = object_track_result[frame_idx]\n",
    "    per_frame_per_object_mask = per_frame_object_result['pred_mask']\n",
    "    per_frame_per_object_iou = per_frame_object_result['pred_iou']\n",
    "    per_frame_per_object_score = per_frame_object_result['pred_object_score']\n",
    "\n",
    "    per_frame_per_object_mask = per_frame_per_object_mask > 0.\n",
    "\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    show_image = Image.open(frames_path_list[frame_idx])\n",
    "    plt.imshow(show_image)\n",
    "    show_mask(per_frame_per_object_mask, plt.gca(), obj_id=tracking_object_id)\n",
    "    plt.title(\n",
    "        f\"frame: {frame_idx}, IoU Score: {per_frame_per_object_iou:.3f}, Object Score: {per_frame_per_object_score:.3f}\",\n",
    "        fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3f9ba7-bf4d-47e5-9b02-8a424cab42cc",
   "metadata": {},
   "source": [
    "# Clear Video State Dict All Object Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54906315-ab4c-4088-b866-4c22134d5b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_state_dict = sam2_model.clear_video_state_dict_all_object_info(video_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6888a9",
   "metadata": {},
   "source": [
    "# Add one object with box prompt at final frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d80c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx = 199\n",
    "\n",
    "# Let's add a box at (x_min, y_min, x_max, y_max) = (300, 0, 500, 400) to get started\n",
    "input_box = np.array([300, 50, 470, 375], dtype=np.float32)\n",
    "print(input_box.shape)\n",
    "\n",
    "input_prompt_box = np.expand_dims(input_box, axis=0)\n",
    "print(input_prompt_box.shape,input_prompt_box.dtype)\n",
    "\n",
    "exist_object_ids, frame_idx, new_object_id, has_prompt_point, has_prompt_box, has_prompt_mask = sam2_model.add_new_object_prompt_input(\n",
    "                                    video_state_dict,\n",
    "                                    frame_idx=frame_idx,\n",
    "                                    prompt_point=None,\n",
    "                                    prompt_box=input_prompt_box,\n",
    "                                    prompt_mask=None)\n",
    "print(exist_object_ids, frame_idx, new_object_id, has_prompt_point, has_prompt_box, has_prompt_mask)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.title(f\"frame {frame_idx}\")\n",
    "show_image = Image.open(frames_path_list[frame_idx])\n",
    "plt.imshow(show_image)\n",
    "show_box(input_box, plt.gca())\n",
    "\n",
    "mask_preds, iou_preds = sam2_model.forward_one_image_test(video_state_dict, new_object_id, frame_idx, mask_out_idxs=[0])\n",
    "mask_preds, iou_preds = mask_preds[0][0], iou_preds[0][0]\n",
    "binary_mask_preds = mask_preds > 0.\n",
    "binary_mask_preds = binary_mask_preds.cpu().float().numpy()\n",
    "iou_preds = iou_preds.cpu().float().numpy()\n",
    "print(binary_mask_preds.shape, iou_preds.shape, iou_preds)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "show_image = Image.open(frames_path_list[frame_idx])\n",
    "plt.imshow(show_image)\n",
    "show_mask(binary_mask_preds, plt.gca())\n",
    "show_box(input_box, plt.gca())\n",
    "plt.title(f\"frame {frame_idx}, Score: {iou_preds:.3f}\", fontsize=18)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b9245e",
   "metadata": {},
   "source": [
    "# Tracking one object with box prompt at final frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71677696",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_object_id = 0\n",
    "video_state_dict = sam2_model.forward_tracking_for_test(video_state_dict, start_tracking_frame_idx=199, tracking_object_ids=[tracking_object_id], use_point_prompt_input=False,use_box_prompt_input=True, use_mask_prompt_input=False)\n",
    "\n",
    "frame_num = video_state_dict['video_frame_num']\n",
    "object_track_state = video_state_dict['object_track_state'][tracking_object_id]\n",
    "object_track_result = video_state_dict['object_track_result'][tracking_object_id]\n",
    "print(frame_num, object_track_state)\n",
    "\n",
    "vis_frame_stride = 30\n",
    "for frame_idx in range(0, len(frames_path_list), vis_frame_stride):\n",
    "    per_frame_object_result = object_track_result[frame_idx]\n",
    "    per_frame_per_object_mask = per_frame_object_result['pred_mask']\n",
    "    per_frame_per_object_iou = per_frame_object_result['pred_iou']\n",
    "    per_frame_per_object_score = per_frame_object_result['pred_object_score']\n",
    "\n",
    "    per_frame_per_object_mask = per_frame_per_object_mask > 0.\n",
    "\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    show_image = Image.open(frames_path_list[frame_idx])\n",
    "    plt.imshow(show_image)\n",
    "    show_mask(per_frame_per_object_mask, plt.gca(), obj_id=tracking_object_id)\n",
    "    plt.title(\n",
    "        f\"frame: {frame_idx}, IoU Score: {per_frame_per_object_iou:.3f}, Object Score: {per_frame_per_object_score:.3f}\",\n",
    "        fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2899b485",
   "metadata": {},
   "source": [
    "# Clear Video State Dict All Object Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf2516",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_state_dict = sam2_model.clear_video_state_dict_all_object_info(video_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73128cd6-dbfa-49f7-8d79-1a8e19835f7f",
   "metadata": {},
   "source": [
    "# Add one object with mask prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd90557-a0dc-442e-b091-9c74c831bef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx = 0\n",
    "prompt_mask_path= '/root/code/SimpleAICV_pytorch_training_examples/14.video_interactive_segmentation_training/sam2_predict_example/test_videos/bedroom/00000_prompt_mask_for_target_0.png'\n",
    "\n",
    "input_mask = np.array(Image.open(prompt_mask_path).convert('L'), dtype=np.uint8)\n",
    "input_mask = input_mask / 255.\n",
    "input_mask = input_mask.astype(np.float32)\n",
    "print(input_mask.shape)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.title(f\"frame {frame_idx}\")\n",
    "show_image = Image.open(frames_path_list[frame_idx])\n",
    "plt.imshow(show_image)\n",
    "show_mask(input_mask, plt.gca())\n",
    "\n",
    "input_prompt_mask = input_mask\n",
    "print(input_prompt_mask.shape,input_prompt_mask.dtype)\n",
    "\n",
    "exist_object_ids, frame_idx, new_object_id, has_prompt_point, has_prompt_box, has_prompt_mask = sam2_model.add_new_object_prompt_input(\n",
    "                                    video_state_dict,\n",
    "                                    frame_idx=frame_idx,\n",
    "                                    prompt_point=None,\n",
    "                                    prompt_box=None,\n",
    "                                    prompt_mask=input_prompt_mask)\n",
    "print(exist_object_ids, frame_idx, new_object_id, has_prompt_point, has_prompt_box, has_prompt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e023f91f-0cc5-4980-ae8e-a13c5749112b",
   "metadata": {},
   "source": [
    "# Tracking one object with mask prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b874c8-9f39-42d3-a667-54a0bd696410",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_object_id = 0\n",
    "video_state_dict = sam2_model.forward_tracking_for_test(video_state_dict, start_tracking_frame_idx=0, tracking_object_ids=[tracking_object_id], use_point_prompt_input=False,use_box_prompt_input=False, use_mask_prompt_input=True)\n",
    "\n",
    "frame_num = video_state_dict['video_frame_num']\n",
    "object_track_state = video_state_dict['object_track_state'][tracking_object_id]\n",
    "object_track_result = video_state_dict['object_track_result'][tracking_object_id]\n",
    "print(frame_num, object_track_state)\n",
    "\n",
    "vis_frame_stride = 30\n",
    "for frame_idx in range(0, len(frames_path_list), vis_frame_stride):\n",
    "    per_frame_object_result = object_track_result[frame_idx]\n",
    "    per_frame_per_object_mask = per_frame_object_result['pred_mask']\n",
    "    per_frame_per_object_iou = per_frame_object_result['pred_iou']\n",
    "    per_frame_per_object_score = per_frame_object_result['pred_object_score']\n",
    "\n",
    "    per_frame_per_object_mask = per_frame_per_object_mask > 0.\n",
    "\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    show_image = Image.open(frames_path_list[frame_idx])\n",
    "    plt.imshow(show_image)\n",
    "    show_mask(per_frame_per_object_mask, plt.gca(), obj_id=tracking_object_id)\n",
    "    plt.title(\n",
    "        f\"frame: {frame_idx}, IoU Score: {per_frame_per_object_iou:.3f}, Object Score: {per_frame_per_object_score:.3f}\",\n",
    "        fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f3f7e6-4821-468c-84e4-f3a0435c9149",
   "metadata": {},
   "source": [
    "# Clear Video State Dict All Object Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d896d-3cd5-4fa0-9230-f33e217035dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_state_dict = sam2_model.clear_video_state_dict_all_object_info(video_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d9ac57-b14a-4237-828d-927e422c518b",
   "metadata": {},
   "source": [
    "# Add two object with box prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13432fc-f467-44d8-adfe-3e0c488046b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx = 0\n",
    "\n",
    "# Let's add a box at (x_min, y_min, x_max, y_max) = (150, 130, 290, 410) to get started\n",
    "input_box = np.array([150, 130, 290, 410], dtype=np.float32)\n",
    "print(input_box.shape)\n",
    "\n",
    "input_prompt_box = np.expand_dims(input_box, axis=0)\n",
    "print(input_prompt_box.shape,input_prompt_box.dtype)\n",
    "\n",
    "exist_object_ids, frame_idx, new_object_id, has_prompt_point, has_prompt_box, has_prompt_mask = sam2_model.add_new_object_prompt_input(\n",
    "                                    video_state_dict,\n",
    "                                    frame_idx=frame_idx,\n",
    "                                    prompt_point=None,\n",
    "                                    prompt_box=input_prompt_box,\n",
    "                                    prompt_mask=None)\n",
    "print(exist_object_ids, frame_idx, new_object_id, has_prompt_point, has_prompt_box, has_prompt_mask)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.title(f\"frame {frame_idx}\")\n",
    "show_image = Image.open(frames_path_list[frame_idx])\n",
    "plt.imshow(show_image)\n",
    "show_box(input_box, plt.gca())\n",
    "\n",
    "mask_preds, iou_preds = sam2_model.forward_one_image_test(video_state_dict, new_object_id, frame_idx, mask_out_idxs=[0])\n",
    "mask_preds, iou_preds = mask_preds[0][0], iou_preds[0][0]\n",
    "binary_mask_preds = mask_preds > 0.\n",
    "binary_mask_preds = binary_mask_preds.cpu().float().numpy()\n",
    "iou_preds = iou_preds.cpu().float().numpy()\n",
    "print(binary_mask_preds.shape, iou_preds.shape, iou_preds)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "show_image = Image.open(frames_path_list[frame_idx])\n",
    "plt.imshow(show_image)\n",
    "show_mask(binary_mask_preds, plt.gca())\n",
    "show_box(input_box, plt.gca())\n",
    "plt.title(f\"frame {frame_idx}, Score: {iou_preds:.3f}\", fontsize=18)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ecf61d-662b-4f98-ae62-46557b219842",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx = 0\n",
    "\n",
    "# Let's add a box at (x_min, y_min, x_max, y_max) = (300, 0, 500, 400) to get started\n",
    "input_box = np.array([300, 0, 500, 400], dtype=np.float32)\n",
    "print(input_box.shape)\n",
    "\n",
    "input_prompt_box = np.expand_dims(input_box, axis=0)\n",
    "print(input_prompt_box.shape,input_prompt_box.dtype)\n",
    "\n",
    "exist_object_ids, frame_idx, new_object_id, has_prompt_point, has_prompt_box, has_prompt_mask = sam2_model.add_new_object_prompt_input(\n",
    "                                    video_state_dict,\n",
    "                                    frame_idx=frame_idx,\n",
    "                                    prompt_point=None,\n",
    "                                    prompt_box=input_prompt_box,\n",
    "                                    prompt_mask=None)\n",
    "print(exist_object_ids, frame_idx, new_object_id, has_prompt_point, has_prompt_box, has_prompt_mask)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.title(f\"frame {frame_idx}\")\n",
    "show_image = Image.open(frames_path_list[frame_idx])\n",
    "plt.imshow(show_image)\n",
    "show_box(input_box, plt.gca())\n",
    "\n",
    "mask_preds, iou_preds = sam2_model.forward_one_image_test(video_state_dict, new_object_id, frame_idx, mask_out_idxs=[0])\n",
    "mask_preds, iou_preds = mask_preds[0][0], iou_preds[0][0]\n",
    "binary_mask_preds = mask_preds > 0.\n",
    "binary_mask_preds = binary_mask_preds.cpu().float().numpy()\n",
    "iou_preds = iou_preds.cpu().float().numpy()\n",
    "print(binary_mask_preds.shape, iou_preds.shape, iou_preds)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "show_image = Image.open(frames_path_list[frame_idx])\n",
    "plt.imshow(show_image)\n",
    "show_mask(binary_mask_preds, plt.gca())\n",
    "show_box(input_box, plt.gca())\n",
    "plt.title(f\"frame {frame_idx}, Score: {iou_preds:.3f}\", fontsize=18)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194718c1-734d-446c-a3ef-361057de2f31",
   "metadata": {},
   "source": [
    "# Tracking two object with box prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ca1bde-62a4-40e6-98e4-15606441e52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_object_ids = [0, 1]\n",
    "video_state_dict = sam2_model.forward_tracking_for_test(video_state_dict, start_tracking_frame_idx=0, tracking_object_ids=tracking_object_ids, use_point_prompt_input=False,use_box_prompt_input=True, use_mask_prompt_input=False)\n",
    "\n",
    "frame_num = video_state_dict['video_frame_num']\n",
    "object_track_state_0 = video_state_dict['object_track_state'][0]\n",
    "object_track_result_0 = video_state_dict['object_track_result'][0]\n",
    "print(frame_num, object_track_state_0)\n",
    "\n",
    "vis_frame_stride = 30\n",
    "for frame_idx in range(0, len(frames_path_list), vis_frame_stride):\n",
    "    per_frame_object_result = object_track_result_0[frame_idx]\n",
    "    per_frame_per_object_mask = per_frame_object_result['pred_mask']\n",
    "    per_frame_per_object_iou = per_frame_object_result['pred_iou']\n",
    "    per_frame_per_object_score = per_frame_object_result['pred_object_score']\n",
    "\n",
    "    per_frame_per_object_mask = per_frame_per_object_mask > 0.\n",
    "\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    show_image = Image.open(frames_path_list[frame_idx])\n",
    "    plt.imshow(show_image)\n",
    "    show_mask(per_frame_per_object_mask, plt.gca(), obj_id=0)\n",
    "    plt.title(\n",
    "        f\"frame: {frame_idx}, IoU Score: {per_frame_per_object_iou:.3f}, Object Score: {per_frame_per_object_score:.3f}\",\n",
    "        fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "frame_num = video_state_dict['video_frame_num']\n",
    "object_track_state_1 = video_state_dict['object_track_state'][1]\n",
    "object_track_result_1 = video_state_dict['object_track_result'][1]\n",
    "print(frame_num, object_track_state_1)\n",
    "\n",
    "vis_frame_stride = 30\n",
    "for frame_idx in range(0, len(frames_path_list), vis_frame_stride):\n",
    "    per_frame_object_result = object_track_result_1[frame_idx]\n",
    "    per_frame_per_object_mask = per_frame_object_result['pred_mask']\n",
    "    per_frame_per_object_iou = per_frame_object_result['pred_iou']\n",
    "    per_frame_per_object_score = per_frame_object_result['pred_object_score']\n",
    "\n",
    "    per_frame_per_object_mask = per_frame_per_object_mask > 0.\n",
    "\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    show_image = Image.open(frames_path_list[frame_idx])\n",
    "    plt.imshow(show_image)\n",
    "    show_mask(per_frame_per_object_mask, plt.gca(), obj_id=1)\n",
    "    plt.title(\n",
    "        f\"frame: {frame_idx}, IoU Score: {per_frame_per_object_iou:.3f}, Object Score: {per_frame_per_object_score:.3f}\",\n",
    "        fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
