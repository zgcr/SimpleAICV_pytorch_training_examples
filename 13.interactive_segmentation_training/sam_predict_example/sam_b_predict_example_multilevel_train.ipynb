{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bc90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb1927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "inference_ipynb_path='/root/code/SimpleAICV_pytorch_training_examples/13.interactive_segmentation_training/sam_predict_example'\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(inference_ipynb_path))\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from SimpleAICV.interactive_segmentation.models.segment_anything.sam import sam_b\n",
    "from SimpleAICV.interactive_segmentation.common import load_state_dict\n",
    "\n",
    "\n",
    "sam_checkpoint = '/root/autodl-tmp/pretrained_models/sam_segmentation_train_on_interactive_segmentation_dataset/sam_b_multilevel_epoch_2.pth'\n",
    "\n",
    "sam_model = sam_b()\n",
    "sam_model = sam_model.cuda()\n",
    "sam_model = sam_model.eval()\n",
    "\n",
    "load_state_dict(sam_checkpoint,sam_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c013927",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path='/root/code/SimpleAICV_pytorch_training_examples/13.interactive_segmentation_training/sam_predict_example/test_images/truck.jpg'\n",
    "origin_image = cv2.imdecode(np.fromfile(test_image_path, dtype=np.uint8),\n",
    "                        cv2.IMREAD_COLOR)\n",
    "origin_image = cv2.cvtColor(origin_image, cv2.COLOR_BGR2RGB)\n",
    "print(origin_image.shape,origin_image.dtype)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(origin_image)\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca1f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_h, origin_w = origin_image.shape[0], origin_image.shape[1]\n",
    "factor = 1024 / max(origin_h, origin_w)\n",
    "resize_h, resize_w = int(round(origin_h * factor)), int(\n",
    "    round(origin_w * factor))\n",
    "resized_image = cv2.resize(origin_image, (resize_w, resize_h))\n",
    "print(resized_image.shape,resized_image.dtype,factor)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(resized_image)\n",
    "plt.axis('on')\n",
    "plt.show()\n",
    "\n",
    "mean = [123.675, 116.28, 103.53]\n",
    "std = [58.395, 57.12, 57.375]\n",
    "norm_image = (resized_image - mean) / std\n",
    "print(norm_image.shape,np.max(norm_image),np.min(norm_image))\n",
    "\n",
    "padded_img = np.zeros((max(resize_h, resize_w), max(resize_h, resize_w), 3),\n",
    "                        dtype=np.float32)\n",
    "padded_img[:resize_h, :resize_w, :] = norm_image\n",
    "print(padded_img.shape,np.max(padded_img),np.min(padded_img))\n",
    "\n",
    "padded_img = torch.tensor(padded_img).float().cuda().permute(2, 0, 1).unsqueeze(0)\n",
    "print(padded_img.shape,torch.max(padded_img),torch.min(padded_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91ba973",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_point = np.array([[500, 375]])*factor\n",
    "# if positive point, input label = 1 ,elif negative point, input label = 0\n",
    "input_label = np.array([[1]])\n",
    "print(input_point.shape,input_label.shape)\n",
    "\n",
    "prompt_point=np.concatenate([input_point,input_label],axis=1)\n",
    "print(prompt_point.shape)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(resized_image)\n",
    "show_points(input_point, input_label[0], plt.gca())\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c765e952",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt_point = torch.tensor(np.expand_dims(prompt_point,axis=0)).float().cuda()\n",
    "print(padded_img.shape,input_prompt_point.shape,padded_img.dtype,input_prompt_point.dtype)\n",
    "\n",
    "batch_images = padded_img.clone()\n",
    "batch_prompts = {'prompt_point':input_prompt_point,\n",
    "                'prompt_box':None,\n",
    "                'prompt_mask':None}\n",
    "\n",
    "with torch.no_grad():\n",
    "    mask_preds, iou_preds = sam_model(batch_images, batch_prompts, mask_out_idxs=[0, 1, 2, 3])\n",
    "    mask_preds, iou_preds = mask_preds[0], iou_preds[0]\n",
    "    binary_mask_preds = mask_preds > 0.\n",
    "print(mask_preds.shape,iou_preds.shape,iou_preds)\n",
    "\n",
    "for i, (mask, score) in enumerate(zip(binary_mask_preds, iou_preds)):\n",
    "    mask=mask.cpu().numpy()\n",
    "    score=score.cpu().numpy()\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(resized_image)\n",
    "    show_mask(mask, plt.gca())\n",
    "    show_points(input_point, input_label[0], plt.gca())\n",
    "    plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d6d29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_point = np.array([[500, 375], [1125, 625]])*factor\n",
    "input_label = np.array([[1], [1]])\n",
    "print(input_point.shape,input_label.shape)\n",
    "\n",
    "prompt_point = np.concatenate([input_point,input_label],axis=1)\n",
    "print(prompt_point.shape)\n",
    "\n",
    "# Choose the model's best mask\n",
    "prompt_mask = binary_mask_preds.clone().unsqueeze(0).float()\n",
    "prompt_mask = F.interpolate(prompt_mask,(256, 256), mode = \"nearest\")\n",
    "input_prompt_mask = prompt_mask[:,3:4,:,:]\n",
    "print(input_prompt_mask.shape)\n",
    "\n",
    "input_prompt_point = torch.tensor(np.expand_dims(prompt_point,axis=0)).float().cuda()\n",
    "print(padded_img.shape,input_prompt_point.shape,padded_img.dtype,input_prompt_point.dtype)\n",
    "\n",
    "batch_images = padded_img.clone()\n",
    "batch_prompts = {'prompt_point':input_prompt_point,\n",
    "                'prompt_box':None,\n",
    "                'prompt_mask':input_prompt_mask}\n",
    "\n",
    "with torch.no_grad():\n",
    "    mask_preds, iou_preds = sam_model(batch_images, batch_prompts, mask_out_idxs=[0, 1, 2, 3])\n",
    "    mask_preds, iou_preds = mask_preds[0], iou_preds[0]\n",
    "    binary_mask_preds = mask_preds > 0.\n",
    "print(mask_preds.shape,iou_preds.shape,iou_preds)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(resized_image)\n",
    "show_mask(binary_mask_preds.cpu().numpy()[0], plt.gca())\n",
    "show_points(input_point, np.squeeze(input_label,axis=1), plt.gca())\n",
    "plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e2087",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_point = np.array([[500, 375], [1125, 625]])*factor\n",
    "input_label = np.array([[1], [0]])\n",
    "print(input_point.shape,input_label.shape)\n",
    "\n",
    "prompt_point = np.concatenate([input_point,input_label],axis=1)\n",
    "print(prompt_point.shape)\n",
    "\n",
    "# Choose the model's best mask\n",
    "prompt_mask = binary_mask_preds.clone().unsqueeze(0).float()\n",
    "prompt_mask = F.interpolate(prompt_mask,(256, 256), mode = \"nearest\")\n",
    "input_prompt_mask = prompt_mask[:,1:2,:,:]\n",
    "print(input_prompt_mask.shape)\n",
    "\n",
    "input_prompt_point = torch.tensor(np.expand_dims(prompt_point,axis=0)).float().cuda()\n",
    "print(padded_img.shape,input_prompt_point.shape,padded_img.dtype,input_prompt_point.dtype)\n",
    "\n",
    "batch_images = padded_img.clone()\n",
    "batch_prompts = {'prompt_point':input_prompt_point,\n",
    "                'prompt_box':None,\n",
    "                'prompt_mask':input_prompt_mask}\n",
    "\n",
    "with torch.no_grad():\n",
    "    mask_preds, iou_preds = sam_model(batch_images, batch_prompts, mask_out_idxs=[0, 1, 2, 3])\n",
    "    mask_preds, iou_preds = mask_preds[0], iou_preds[0]\n",
    "    binary_mask_preds = mask_preds > 0.\n",
    "print(mask_preds.shape,iou_preds.shape,iou_preds)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(resized_image)\n",
    "show_mask(binary_mask_preds.cpu().numpy()[0], plt.gca())\n",
    "show_points(input_point, np.squeeze(input_label,axis=1), plt.gca())\n",
    "plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61ca7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_box = np.array([425, 600, 700, 875])*factor\n",
    "\n",
    "input_prompt_box = torch.tensor(np.expand_dims(input_box,axis=0)).float().cuda()\n",
    "print(padded_img.shape,input_prompt_box.shape,padded_img.dtype,input_prompt_box.dtype)\n",
    "\n",
    "batch_images = padded_img.clone()\n",
    "batch_prompts = {'prompt_point':None,\n",
    "                'prompt_box':input_prompt_box,\n",
    "                'prompt_mask':None}\n",
    "\n",
    "with torch.no_grad():\n",
    "    mask_preds, iou_preds = sam_model(batch_images, batch_prompts, mask_out_idxs=[0, 1, 2, 3])\n",
    "    mask_preds, iou_preds = mask_preds[0], iou_preds[0]\n",
    "    binary_mask_preds = mask_preds > 0.\n",
    "print(mask_preds.shape,iou_preds.shape,iou_preds)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(resized_image)\n",
    "show_mask(binary_mask_preds.cpu().numpy()[0], plt.gca())\n",
    "show_box(input_box, plt.gca())\n",
    "plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8455d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_box = np.array([425, 600, 700, 875])*factor\n",
    "input_point = np.array([[575, 750]])*factor\n",
    "input_label = np.array([[0]])\n",
    "print(input_box.shape,input_point.shape,input_label.shape)\n",
    "\n",
    "prompt_point = np.concatenate([input_point,input_label],axis=1)\n",
    "print(prompt_point.shape)\n",
    "\n",
    "input_prompt_point = torch.tensor(np.expand_dims(prompt_point,axis=0)).float().cuda()\n",
    "print(padded_img.shape,input_prompt_point.shape,padded_img.dtype,input_prompt_point.dtype)\n",
    "\n",
    "input_prompt_box = torch.tensor(np.expand_dims(input_box,axis=0)).float().cuda()\n",
    "print(padded_img.shape,input_prompt_box.shape,padded_img.dtype,input_prompt_box.dtype)\n",
    "\n",
    "batch_images = padded_img.clone()\n",
    "batch_prompts = {'prompt_point':input_prompt_point,\n",
    "                'prompt_box':input_prompt_box,\n",
    "                'prompt_mask':None}\n",
    "\n",
    "with torch.no_grad():\n",
    "    mask_preds, iou_preds = sam_model(batch_images, batch_prompts, mask_out_idxs=[0, 1, 2, 3])\n",
    "    mask_preds, iou_preds = mask_preds[0], iou_preds[0]\n",
    "    binary_mask_preds = mask_preds > 0.\n",
    "print(mask_preds.shape,iou_preds.shape,iou_preds)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(resized_image)\n",
    "show_mask(binary_mask_preds.cpu().numpy()[0], plt.gca())\n",
    "show_box(input_box, plt.gca())\n",
    "show_points(input_point, input_label[0], plt.gca())\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8babcaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_images = padded_img.clone()\n",
    "\n",
    "with torch.no_grad():\n",
    "    per_image_embedding = sam_model.forward_image_encoder(per_images)\n",
    "print(per_image_embedding.shape)\n",
    "\n",
    "input_boxes = np.array([\n",
    "    [75, 275, 1725, 850],\n",
    "    [425, 600, 700, 875],\n",
    "    [1375, 550, 1650, 800],\n",
    "    [1240, 675, 1400, 750]])*factor\n",
    "print(input_boxes.shape)\n",
    "\n",
    "batch_masks = []\n",
    "for per_box in input_boxes:\n",
    "    per_prompt_box = torch.tensor(np.expand_dims(per_box,\n",
    "                                                 axis=0)).float().cuda()\n",
    "    per_prompt = {\n",
    "        'prompt_point': None,\n",
    "        'prompt_box': per_prompt_box,\n",
    "        'prompt_mask': None\n",
    "    }\n",
    "    mask_out_idxs = [0]\n",
    "    with torch.no_grad():\n",
    "        mask_preds, iou_preds = sam_model.forward_prompt_encoder_mask_decoder(\n",
    "            per_image_embedding, per_prompt, mask_out_idxs=mask_out_idxs)\n",
    "        mask_preds, iou_preds = mask_preds[0], iou_preds[0]\n",
    "        binary_mask_preds = mask_preds > 0.\n",
    "    print(mask_preds.shape, iou_preds.shape, iou_preds)\n",
    "\n",
    "    batch_masks.append(binary_mask_preds)\n",
    "print(len(batch_masks))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(resized_image)\n",
    "for idx, (per_mask, per_box) in enumerate(zip(batch_masks, input_boxes)):\n",
    "    per_mask=per_mask.cpu().numpy()[0]\n",
    "    show_mask(per_mask, plt.gca(), random_color=True)\n",
    "    show_box(per_box, plt.gca())\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bea70c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path2='/root/code/SimpleAICV_pytorch_training_examples/13.interactive_segmentation_training/sam_predict_example/test_images/groceries.jpg'\n",
    "origin_image2 = cv2.imdecode(np.fromfile(test_image_path2, dtype=np.uint8),\n",
    "                        cv2.IMREAD_COLOR)\n",
    "origin_image2 = cv2.cvtColor(origin_image2, cv2.COLOR_BGR2RGB)\n",
    "origin_h2, origin_w2 = origin_image2.shape[0], origin_image2.shape[1]\n",
    "factor2 = 1024 / max(origin_h2, origin_w2)\n",
    "resize_h2, resize_w2 = int(round(origin_h2 * factor2)), int(\n",
    "    round(origin_w2 * factor2))\n",
    "resized_image2 = cv2.resize(origin_image2, (resize_w2, resize_h2))\n",
    "print(resized_image2.shape,resized_image2.dtype,factor2)\n",
    "\n",
    "mean = [123.675, 116.28, 103.53]\n",
    "std = [58.395, 57.12, 57.375]\n",
    "norm_image2 = (resized_image2 - mean) / std\n",
    "print(norm_image2.shape,np.max(norm_image2),np.min(norm_image2))\n",
    "\n",
    "padded_img2 = np.zeros((max(resize_h2, resize_w2), max(resize_h2, resize_w2), 3),\n",
    "                        dtype=np.float32)\n",
    "padded_img2[:resize_h2, :resize_w2, :] = norm_image2\n",
    "print(padded_img2.shape,np.max(padded_img2),np.min(padded_img2))\n",
    "\n",
    "padded_img2 = torch.tensor(padded_img2).float().cuda().permute(2, 0, 1).unsqueeze(0)\n",
    "print(padded_img2.shape,torch.max(padded_img2),torch.min(padded_img2))\n",
    "\n",
    "per_images2 = padded_img2.clone()\n",
    "\n",
    "with torch.no_grad():\n",
    "    per_image_embedding = sam_model.forward_image_encoder(per_images2)\n",
    "print(per_image_embedding.shape)\n",
    "\n",
    "input_boxes2 = np.array([\n",
    "    [450, 170, 520, 350],\n",
    "    [350, 190, 450, 350],\n",
    "    [500, 170, 580, 350],\n",
    "    [580, 170, 640, 350]])*factor2\n",
    "\n",
    "batch_masks2 = []\n",
    "for per_box in input_boxes2:\n",
    "    per_prompt_box = torch.tensor(np.expand_dims(per_box,\n",
    "                                                 axis=0)).float().cuda()\n",
    "    per_prompt = {\n",
    "        'prompt_point': None,\n",
    "        'prompt_box': per_prompt_box,\n",
    "        'prompt_mask': None\n",
    "    }\n",
    "    mask_out_idxs = [0]\n",
    "    with torch.no_grad():\n",
    "        mask_preds, iou_preds = sam_model.forward_prompt_encoder_mask_decoder(\n",
    "            per_image_embedding, per_prompt, mask_out_idxs=mask_out_idxs)\n",
    "        mask_preds, iou_preds = mask_preds[0], iou_preds[0]\n",
    "        binary_mask_preds = mask_preds > 0.\n",
    "    print(mask_preds.shape, iou_preds.shape, iou_preds)\n",
    "\n",
    "    batch_masks2.append(binary_mask_preds)\n",
    "print(len(batch_masks2))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(resized_image2)\n",
    "for idx, (per_mask, per_box) in enumerate(zip(batch_masks2, input_boxes2)):\n",
    "    per_mask=per_mask.cpu().numpy()[0]\n",
    "    show_mask(per_mask, plt.gca(), random_color=True)\n",
    "    show_box(per_box, plt.gca())\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
