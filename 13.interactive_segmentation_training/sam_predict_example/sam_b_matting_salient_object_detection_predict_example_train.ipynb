{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bc90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb1927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "inference_ipynb_path='/root/code/SimpleAICV_pytorch_training_examples/13.interactive_segmentation_training/sam_predict_example'\n",
    "BASE_DIR = os.path.dirname(os.path.dirname(inference_ipynb_path))\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from SimpleAICV.interactive_segmentation.models.segment_anything_matting import sam_b_matting\n",
    "from SimpleAICV.interactive_segmentation.common import load_state_dict\n",
    "\n",
    "\n",
    "sam_checkpoint = ''\n",
    "\n",
    "sam_model = sam_b_matting()\n",
    "sam_model = sam_model.cuda()\n",
    "sam_model = sam_model.eval()\n",
    "\n",
    "load_state_dict(sam_checkpoint,sam_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c013927",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path='/root/code/SimpleAICV_pytorch_training_examples/13.interactive_segmentation_training/sam_predict_example/test_salient_object_detection_images/HRSOD_10113619975_0b1690a93d_k.jpg'\n",
    "origin_image = cv2.imdecode(np.fromfile(test_image_path, dtype=np.uint8),\n",
    "                        cv2.IMREAD_COLOR)\n",
    "origin_image = cv2.cvtColor(origin_image, cv2.COLOR_BGR2RGB)\n",
    "print(origin_image.shape,origin_image.dtype)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(origin_image)\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca1f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_h, origin_w = origin_image.shape[0], origin_image.shape[1]\n",
    "factor = 1024 / max(origin_h, origin_w)\n",
    "resize_h, resize_w = int(round(origin_h * factor)), int(\n",
    "    round(origin_w * factor))\n",
    "resized_image = cv2.resize(origin_image, (resize_w, resize_h))\n",
    "print(resized_image.shape,resized_image.dtype,factor)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(resized_image)\n",
    "plt.axis('on')\n",
    "plt.show()\n",
    "\n",
    "mean = [123.675, 116.28, 103.53]\n",
    "std = [58.395, 57.12, 57.375]\n",
    "norm_image = (resized_image - mean) / std\n",
    "print(norm_image.shape,np.max(norm_image),np.min(norm_image))\n",
    "\n",
    "padded_img = np.zeros((max(resize_h, resize_w), max(resize_h, resize_w), 3),\n",
    "                        dtype=np.float32)\n",
    "padded_img[:resize_h, :resize_w, :] = norm_image\n",
    "print(padded_img.shape,np.max(padded_img),np.min(padded_img))\n",
    "\n",
    "padded_img = torch.tensor(padded_img).float().cuda().permute(2, 0, 1).unsqueeze(0)\n",
    "print(padded_img.shape,torch.max(padded_img),torch.min(padded_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91ba973",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_point = np.array([[1000, 600]])*factor\n",
    "# if positive point, input label = 1 ,elif negative point, input label = 0\n",
    "input_label = np.array([[1]])\n",
    "print(input_point.shape,input_label.shape)\n",
    "\n",
    "prompt_point=np.concatenate([input_point,input_label],axis=1)\n",
    "print(prompt_point.shape)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(resized_image)\n",
    "show_points(input_point, input_label[0], plt.gca())\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c765e952",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt_point = torch.tensor(np.expand_dims(prompt_point,axis=0)).float().cuda()\n",
    "print(padded_img.shape,input_prompt_point.shape,padded_img.dtype,input_prompt_point.dtype)\n",
    "\n",
    "batch_images = padded_img.clone()\n",
    "batch_prompts = {'prompt_point':input_prompt_point,\n",
    "                'prompt_box':None,\n",
    "                'prompt_mask':None}\n",
    "\n",
    "with torch.no_grad():\n",
    "    global_preds, local_preds, fused_preds, iou_preds = sam_model(batch_images, batch_prompts, mask_out_idxs=[0, 1, 2, 3])\n",
    "    global_preds, local_preds, fused_preds, iou_preds = global_preds[0], local_preds[0], fused_preds[0], iou_preds[0]\n",
    "    pred_mask = fused_preds.cpu().numpy()\n",
    "    pred_iou = iou_preds.cpu().numpy()\n",
    "print(pred_mask.shape,pred_iou.shape,pred_iou)\n",
    "\n",
    "for i, (per_pred_mask, per_pred_iou) in enumerate(zip(pred_mask, pred_iou)):\n",
    "    show_image = resized_image.astype(np.float32)\n",
    "    per_pred_mask = np.squeeze(per_pred_mask,axis=0)\n",
    "\n",
    "    # 创建绿色背景\n",
    "    green_background = np.zeros_like(show_image, dtype=np.float32)\n",
    "    # RGB格式\n",
    "    green_background[:, :] = [0, 255, 0]  \n",
    "\n",
    "    per_pred_mask = per_pred_mask[:show_image.shape[0], :show_image.shape[1]]\n",
    "    per_pred_mask = np.expand_dims(per_pred_mask, axis=-1)\n",
    "    print(show_image.shape, green_background.shape, per_pred_mask.shape, np.max(show_image),\n",
    "          np.min(show_image), np.max(per_pred_mask), np.min(per_pred_mask))\n",
    "\n",
    "    # 得到前景区域和背景区域并合并\n",
    "    foreground = show_image * per_pred_mask\n",
    "    background = green_background * (1 - per_pred_mask)\n",
    "    result_image = foreground + background\n",
    "\n",
    "    foreground = foreground.astype(np.uint8)\n",
    "    background = background.astype(np.uint8)\n",
    "    result_image = result_image.astype(np.uint8)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(foreground)\n",
    "    show_points(input_point, input_label[0], plt.gca())\n",
    "    plt.title(f\"idx: {i}, foreground: IoU Score{per_pred_iou:.3f}\", fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(background)\n",
    "    show_points(input_point, input_label[0], plt.gca())\n",
    "    plt.title(f\"idx: {i}, background: IoU Score{per_pred_iou:.3f}\", fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(result_image)\n",
    "    show_points(input_point, input_label[0], plt.gca())\n",
    "    plt.title(f\"idx: {i}, result_image: IoU Score{per_pred_iou:.3f}\", fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(per_pred_mask)\n",
    "    show_points(input_point, input_label[0], plt.gca())\n",
    "    plt.title(f\"idx: {i}, pred_mask: IoU Score{per_pred_iou:.3f}\", fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5a90a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_box = np.array([300, 200, 1650, 1250])*factor\n",
    "\n",
    "input_prompt_box = torch.tensor(np.expand_dims(input_box,axis=0)).float().cuda()\n",
    "print(padded_img.shape,input_prompt_box.shape,padded_img.dtype,input_prompt_box.dtype)\n",
    "\n",
    "batch_images = padded_img.clone()\n",
    "batch_prompts = {'prompt_point':None,\n",
    "                'prompt_box':input_prompt_box,\n",
    "                'prompt_mask':None}\n",
    "\n",
    "with torch.no_grad():\n",
    "    global_preds, local_preds, fused_preds, iou_preds = sam_model(batch_images, batch_prompts, mask_out_idxs=[0, 1, 2, 3])\n",
    "    global_preds, local_preds, fused_preds, iou_preds = global_preds[0], local_preds[0], fused_preds[0], iou_preds[0]\n",
    "    pred_mask = fused_preds.cpu().numpy()\n",
    "    pred_iou = iou_preds.cpu().numpy()\n",
    "print(pred_mask.shape,pred_iou.shape,pred_iou)\n",
    "\n",
    "for i, (per_pred_mask, per_pred_iou) in enumerate(zip(pred_mask, pred_iou)):\n",
    "    show_image = resized_image.astype(np.float32)\n",
    "    per_pred_mask = np.squeeze(per_pred_mask,axis=0)\n",
    "\n",
    "    # 创建绿色背景\n",
    "    green_background = np.zeros_like(show_image, dtype=np.float32)\n",
    "    # RGB格式\n",
    "    green_background[:, :] = [0, 255, 0]  \n",
    "\n",
    "    per_pred_mask = per_pred_mask[:show_image.shape[0], :show_image.shape[1]]\n",
    "    per_pred_mask = np.expand_dims(per_pred_mask, axis=-1)\n",
    "    print(show_image.shape, green_background.shape, per_pred_mask.shape, np.max(show_image),\n",
    "          np.min(show_image), np.max(per_pred_mask), np.min(per_pred_mask))\n",
    "\n",
    "    # 得到前景区域和背景区域并合并\n",
    "    foreground = show_image * per_pred_mask\n",
    "    background = green_background * (1 - per_pred_mask)\n",
    "    result_image = foreground + background\n",
    "\n",
    "    foreground = foreground.astype(np.uint8)\n",
    "    background = background.astype(np.uint8)\n",
    "    result_image = result_image.astype(np.uint8)\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(foreground)\n",
    "    show_box(input_box, plt.gca())\n",
    "    plt.title(f\"idx: {i}, foreground: IoU Score{per_pred_iou:.3f}\", fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(background)\n",
    "    show_box(input_box, plt.gca())\n",
    "    plt.title(f\"idx: {i}, background: IoU Score{per_pred_iou:.3f}\", fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(result_image)\n",
    "    show_box(input_box, plt.gca())\n",
    "    plt.title(f\"idx: {i}, result_image: IoU Score{per_pred_iou:.3f}\", fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(per_pred_mask)\n",
    "    show_box(input_box, plt.gca())\n",
    "    plt.title(f\"idx: {i}, pred_mask: IoU Score{per_pred_iou:.3f}\", fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
